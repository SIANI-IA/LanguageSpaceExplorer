{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformer_lens\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge_model(model_base: str, adapter_path: str):\n",
    "    \"\"\"\n",
    "    Function to load a causal language model and merge an adapter.\n",
    "\n",
    "    Args:\n",
    "    model_base (str): Path or identifier of the base model (e.g. \"EleutherAI/pythia-70m\").\n",
    "    adapter_path (str): Path to the fine-tuned adapter model.\n",
    "\n",
    "    Returns:\n",
    "    model_merged: The merged and unloaded model.\n",
    "    tokenizer: The tokenizer loaded from the adapter.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(adapter_path)\n",
    "    model_id = AutoModelForCausalLM.from_pretrained(model_base)\n",
    "    model = PeftModel.from_pretrained(model_id, adapter_path)    \n",
    "    return model.merge_and_unload(), tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"model_base = \"Qwen/Qwen2-1.5B-Instruct\"\n",
    "adapter_path = \"fine_tuned_model_both_qwen\"\"\"\n",
    "\n",
    "model_base = \"EleutherAI/pythia-70m\"\n",
    "adapter_path = \"fine_tuned_model_both_pythia\"\n",
    "\n",
    "model_merged_tel, tokenizer_tel = load_and_merge_model(model_base, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 510877.47it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_autoregressive = load_dataset('text', data_files={'train': 'data/sentences_train.txt'})\n",
    "samples_tel = []\n",
    "for sample in tqdm(dataset_autoregressive['train']['text']):\n",
    "    if len(sample) > 0:\n",
    "        # Remove all digits from the sample\n",
    "        cleaned_sample = re.sub(r'\\d+|\\.', '', sample)\n",
    "        samples_tel.append(cleaned_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_hooked = transformer_lens.HookedTransformer.from_pretrained(\n",
    "    model_base,\n",
    "    hf_model=model_merged_tel, \n",
    "    tokenizer=tokenizer_tel,\n",
    "    device=device,\n",
    "    move_to_device=True\n",
    ")\n",
    "num_of_layers = 6 #model_merged_tel.config.max_window_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_activations = {\n",
    "    \"activations\": [],\n",
    "    \"task\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DB: 100%|██████████| 150/150 [00:02<00:00, 68.10it/s]\n"
     ]
    }
   ],
   "source": [
    "for text in tqdm(samples_tel, desc=\"Processing DB\"):\n",
    "    _, activations = model_hooked.run_with_cache(text)\n",
    "    vector = []\n",
    "    for layer in range(num_of_layers):\n",
    "        block_act_fn = activations[f'blocks.{layer}.mlp.hook_post'].flatten(1).to(\"cpu\").detach().numpy()\n",
    "        vector.append(block_act_fn)\n",
    "    db_activations[\"activations\"].append(vector)\n",
    "    db_activations[\"task\"].append(\"tel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "adapter_path = \"fine_tuned_model_math_pythia\"\n",
    "model_merged_math, tokenizer_math = load_and_merge_model(model_base, adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 1635525.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_math = load_dataset('json', data_files='./data/arithmatic_expressions.json', split=\"train\")\n",
    "print(dataset_math)\n",
    "samples_math = []\n",
    "for sample in tqdm(dataset_math['text']):\n",
    "    samples_math.append(sample.split(\" = \")[0] + \"=\")\n",
    "samples_math = np.random.choice(samples_math, 150, replace=False)\n",
    "print(len(samples_math))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model EleutherAI/pythia-70m into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model_hooked_math = transformer_lens.HookedTransformer.from_pretrained(\n",
    "    model_base,\n",
    "    hf_model=model_merged_math, \n",
    "    tokenizer=tokenizer_math,\n",
    "    device=device,\n",
    "    move_to_device=True\n",
    ")\n",
    "num_of_layers = 6 #model_merged_tel.config.max_window_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing DB: 100%|██████████| 150/150 [00:02<00:00, 61.10it/s]\n"
     ]
    }
   ],
   "source": [
    "for text in tqdm(samples_math, desc=\"Processing DB\"):\n",
    "    _, activations = model_hooked_math.run_with_cache(text)\n",
    "    vector = []\n",
    "    for layer in range(num_of_layers):\n",
    "        block_act_fn = activations[f'blocks.{layer}.mlp.hook_post'].flatten(1).to(\"cpu\").detach().numpy()\n",
    "        vector.append(block_act_fn)\n",
    "    db_activations[\"activations\"].append(vector)\n",
    "    db_activations[\"task\"].append(\"math\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the activations into a pandas dataframe\n",
    "df_activations = pd.DataFrame(db_activations)\n",
    "\"\"\"df_activations[\"task\"] = db_activations[\"task\"]\n",
    "df_activations = df_activations.melt(id_vars=[\"task\"], var_name=\"layer\", value_name=\"activations\")\"\"\"\n",
    "\n",
    "# save the activations to a file\n",
    "FOLDER = \"results\"\n",
    "df_activations.to_csv(\n",
    "    os.path.join(FOLDER, \"activations.csv\"),\n",
    "    index=False, \n",
    "    sep=\";\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
