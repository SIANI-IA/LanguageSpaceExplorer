{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import F1Score, Precision, Recall\n",
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_folder = os.path.join(\"results\", 'activations.pkl')\n",
    "data_folder = os.path.join(\"results\", 'activations_math.pkl')\n",
    "TASK = \"multiclass\"\n",
    "with open(data_folder, 'rb') as file:\n",
    "    db_activations_loaded = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(86016,)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's determine the maximum size of the arrays\n",
    "activation_shapes = [np.array(activation).shape for activation in db_activations_loaded['activations']]\n",
    "max_size = max(activation_shapes)\n",
    "\n",
    "# Function to pad arrays with zeros to the maximum size\n",
    "def pad_with_zeros(array, size):\n",
    "    return np.pad(array, (0, size - len(array)), mode='constant')\n",
    "\n",
    "# Apply padding to all activations\n",
    "padded_activations = [pad_with_zeros(np.array(activation), max_size[0]) for activation in db_activations_loaded['activations']]\n",
    "\n",
    "# Replace the original activations with the padded ones\n",
    "db_activations_loaded['activations'] = padded_activations\n",
    "\n",
    "# Check the new shape of the first few activations to confirm the change\n",
    "new_activation_shapes = [np.array(activation).shape for activation in db_activations_loaded['activations']]\n",
    "set(new_activation_shapes)  # Should now contain only one shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paso 1: Crear el Dataset personalizado\n",
    "class ActivationDataset(Dataset):\n",
    "    def __init__(self, activations, tasks):\n",
    "        self.activations = torch.tensor(activations, dtype=torch.float32)\n",
    "        self.tasks = torch.tensor(tasks, dtype=torch.long)  # asumiendo que las tareas son clases etiquetadas con enteros\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.activations)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.activations[idx], self.tasks[idx]\n",
    "    \n",
    "\n",
    "# Paso 2: Crear el DataLoader\n",
    "def create_dataloaders(activations, tasks, batch_size=32, val_split=0.2):\n",
    "    dataset = ActivationDataset(activations, tasks)\n",
    "    val_size = int(len(dataset) * val_split)\n",
    "    train_size = len(dataset) - val_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(pl.LightningModule):\n",
    "    def __init__(self, input_size, num_classes, hidden_size=128):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        # Métricas\n",
    "        self.train_acc = torchmetrics.Accuracy(task=TASK, num_classes=num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task=TASK, num_classes=num_classes)\n",
    "        self.test_acc = torchmetrics.Accuracy(task=TASK, num_classes=num_classes)\n",
    "\n",
    "        self.train_f1 = F1Score(num_classes=num_classes, average='macro', task=TASK)\n",
    "        self.val_f1 = F1Score(num_classes=num_classes, average='macro', task=TASK)\n",
    "        self.test_f1 = F1Score(num_classes=num_classes, average='macro', task=TASK)\n",
    "\n",
    "        self.train_precision = Precision(num_classes=num_classes, average='macro', task=TASK)\n",
    "        self.val_precision = Precision(num_classes=num_classes, average='macro', task=TASK)\n",
    "        self.test_precision = Precision(num_classes=num_classes, average='macro', task=TASK)\n",
    "\n",
    "        self.train_recall = Recall(num_classes=num_classes, average='macro', task=TASK)\n",
    "        self.val_recall = Recall(num_classes=num_classes, average='macro', task=TASK)\n",
    "        self.test_recall = Recall(num_classes=num_classes, average='macro', task=TASK)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    # Training Step\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Calcular métricas\n",
    "        acc = self.train_acc(preds, y)\n",
    "        f1 = self.train_f1(preds, y)\n",
    "        precision = self.train_precision(preds, y)\n",
    "        recall = self.train_recall(preds, y)\n",
    "\n",
    "        # Log de métricas\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_f1', f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('train_precision', precision, on_step=False, on_epoch=True)\n",
    "        self.log('train_recall', recall, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # Validation Step\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Calcular métricas\n",
    "        acc = self.val_acc(preds, y)\n",
    "        f1 = self.val_f1(preds, y)\n",
    "        precision = self.val_precision(preds, y)\n",
    "        recall = self.val_recall(preds, y)\n",
    "\n",
    "        # Log de métricas\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_f1', f1, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log('val_precision', precision, on_step=False, on_epoch=True)\n",
    "        self.log('val_recall', recall, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # Test Step (usar el mismo conjunto que validación para calcular los resultados)\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Calcular métricas\n",
    "        acc = self.test_acc(preds, y)\n",
    "        f1 = self.test_f1(preds, y)\n",
    "        precision = self.test_precision(preds, y)\n",
    "        recall = self.test_recall(preds, y)\n",
    "\n",
    "        # Log de métricas\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.log('test_acc', acc, on_step=False, on_epoch=True)\n",
    "        self.log('test_f1', f1, on_step=False, on_epoch=True)\n",
    "        self.log('test_precision', precision, on_step=False, on_epoch=True)\n",
    "        self.log('test_recall', recall, on_step=False, on_epoch=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    # Optimizer configuration\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32246/1552019537.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:274.)\n",
      "  self.activations = torch.tensor(activations, dtype=torch.float32)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/miguel/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name            | Type                | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | fc1             | Linear              | 11.0 M | train\n",
      "1  | fc2             | Linear              | 16.5 K | train\n",
      "2  | fc3             | Linear              | 516    | train\n",
      "3  | train_acc       | MulticlassAccuracy  | 0      | train\n",
      "4  | val_acc         | MulticlassAccuracy  | 0      | train\n",
      "5  | test_acc        | MulticlassAccuracy  | 0      | train\n",
      "6  | train_f1        | MulticlassF1Score   | 0      | train\n",
      "7  | val_f1          | MulticlassF1Score   | 0      | train\n",
      "8  | test_f1         | MulticlassF1Score   | 0      | train\n",
      "9  | train_precision | MulticlassPrecision | 0      | train\n",
      "10 | val_precision   | MulticlassPrecision | 0      | train\n",
      "11 | test_precision  | MulticlassPrecision | 0      | train\n",
      "12 | train_recall    | MulticlassRecall    | 0      | train\n",
      "13 | val_recall      | MulticlassRecall    | 0      | train\n",
      "14 | test_recall     | MulticlassRecall    | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "11.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.0 M    Total params\n",
      "44.109    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miguel/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/miguel/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 50/50 [00:00<00:00, 62.17it/s, v_num=4, val_loss=0.000434, val_acc=1.000, val_f1=1.000, train_loss=7.03e-5, train_acc=1.000, train_f1=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 50/50 [00:00<00:00, 51.59it/s, v_num=4, val_loss=0.000434, val_acc=1.000, val_f1=1.000, train_loss=7.03e-5, train_acc=1.000, train_f1=1.000]\n"
     ]
    }
   ],
   "source": [
    "# Paso 4: Crear el DataLoader y entrenar el modelo\n",
    "# Supongamos que las activations y tasks ya están cargadas como listas de NumPy y listas de etiquetas\n",
    "activations = db_activations_loaded['activations']  # Lista de activaciones (rellenas)\n",
    "tasks = db_activations_loaded['task']  # Lista de tareas/clasificaciones\n",
    "\n",
    "# Convertir tasks a enteros si no lo están ya (asegurarse de que las clases son números)\n",
    "task_mapping = {label: idx for idx, label in enumerate(set(tasks))}  # Un mapeo de etiquetas a números\n",
    "tasks = [task_mapping[task] for task in tasks]  # Convertir tareas a índices numéricos\n",
    "\n",
    "# Crear DataLoader\n",
    "train_loader, val_loader = create_dataloaders(activations, tasks, batch_size=32)\n",
    "\n",
    "# Definir el modelo\n",
    "input_size = len(activations[0])  # El tamaño del vector de entrada\n",
    "num_classes = len(task_mapping)  # El número de clases\n",
    "\n",
    "model = MLPClassifier(input_size=input_size, num_classes=num_classes)\n",
    "\n",
    "# Inicializar el entrenador de PyTorch Lightning\n",
    "trainer = pl.Trainer(max_epochs=10)\n",
    "\n",
    "# Entrenar el modelo\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/miguel/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 13/13 [00:00<00:00, 90.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          test_f1          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0004341716703493148   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_precision       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">        test_recall        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">            1.0            </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         test_f1         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0004341716703493148  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_precision      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m       test_recall       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m           1.0           \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0004341716703493148,\n",
       "  'test_acc': 1.0,\n",
       "  'test_f1': 1.0,\n",
       "  'test_precision': 1.0,\n",
       "  'test_recall': 1.0}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, dataloaders=val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
